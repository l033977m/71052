{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8lPUFYd4hqc",
        "outputId": "a972ee8b-25ae-4ab0-824e-bd5363a33eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "MyDrive\n",
            "/content/drive/My Drive/Colab Notebooks/data\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive\"\n",
        "# Read datasets\n",
        "%cd /content/drive/My Drive/Colab Notebooks/data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask\n",
        "!pip install pyngrok\n",
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZfLY7T9FD0g",
        "outputId": "124a4046-64fd-4263-c286-a1c46a7bf113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.4.24)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283835 sha256=b6ff3b7c177922b058f689cf2e88a05a189002d89c8acab6d6a6bcdc1eac6e20\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer= WordNetLemmatizer()\n",
        "\n",
        "# Modelling\n",
        "from sklearn.model_selection import train_test_split,KFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#Lime\n",
        "!pip install lime\n",
        "from lime import lime_text\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from lime.lime_text import IndexedString,IndexedCharacters\n",
        "from lime.lime_base import LimeBase\n",
        "from lime.lime_text import explanation\n",
        "sns.set(font_scale=1.3)\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "import threading\n",
        "\n",
        "from flask import Flask\n",
        "from pyngrok import ngrok, conf\n",
        "from flask import Flask, request, jsonify, render_template\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from joblib import load"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDllqXXOUVJj",
        "outputId": "b33bdd8b-ae22-4959-c7b1-04704707ff12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.4.24)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "#conf.get_default().auth_token = getpass.getpass()\n",
        "conf.get_default().auth_token = '2fur86Jip3k2YLUlXV8o4tLNZfk_3UmyXMuBUq5gfoXnWnmGt'\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Open a ngrok tunnel to the HTTP server\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}/\\\"\".format(public_url, 5000))\n",
        "\n",
        "# Update any base URLs to use the public ngrok URL\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "\n",
        "model = load_model('BiLSTM-CNN-GRU.h5')\n",
        "\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = load('label_encoder.joblib')\n",
        "\n",
        "\n",
        "# Initialize LIME explainer\n",
        "explainer = LimeTextExplainer(class_names=label_encoder.classes_)\n",
        "\n",
        "tokenizer = load('tokenizer.joblib')\n",
        "\n",
        "def lemmatization(text):\n",
        "    lemmatizer= WordNetLemmatizer()\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    text=[lemmatizer.lemmatize(y) for y in text]\n",
        "\n",
        "    return \" \" .join(text)\n",
        "\n",
        "def remove_stop_words(text):\n",
        "\n",
        "    Text=[i for i in str(text).split() if i not in stop_words]\n",
        "    return \" \".join(Text)\n",
        "\n",
        "def Removing_numbers(text):\n",
        "    text=''.join([i for i in text if not i.isdigit()])\n",
        "    return text\n",
        "\n",
        "def lower_case(text):\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    text=[y.lower() for y in text]\n",
        "\n",
        "    return \" \" .join(text)\n",
        "\n",
        "def Removing_punctuations(text):\n",
        "    ## Remove punctuations\n",
        "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
        "    text = text.replace('؛',\"\", )\n",
        "\n",
        "    ## remove extra whitespace\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text =  \" \".join(text.split())\n",
        "    return text.strip()\n",
        "\n",
        "def Removing_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "def remove_small_sentences(df):\n",
        "    for i in range(len(df)):\n",
        "        if len(df.text.iloc[i].split()) < 3:\n",
        "            df.text.iloc[i] = np.nan\n",
        "\n",
        "def normalize_text(df):\n",
        "    df.Text=df.Text.apply(lambda text : lower_case(text))\n",
        "    df.Text=df.Text.apply(lambda text : remove_stop_words(text))\n",
        "    df.Text=df.Text.apply(lambda text : Removing_numbers(text))\n",
        "    df.Text=df.Text.apply(lambda text : Removing_punctuations(text))\n",
        "    df.Text=df.Text.apply(lambda text : Removing_urls(text))\n",
        "    df.Text=df.Text.apply(lambda text : lemmatization(text))\n",
        "    return df\n",
        "\n",
        "def normalized_sentence(sentence):\n",
        "    sentence= lower_case(sentence)\n",
        "    sentence= remove_stop_words(sentence)\n",
        "    sentence= Removing_numbers(sentence)\n",
        "    sentence= Removing_punctuations(sentence)\n",
        "    sentence= Removing_urls(sentence)\n",
        "    sentence= lemmatization(sentence)\n",
        "    return sentence\n",
        "\n",
        "\n",
        "# Define prediction function\n",
        "def predict(input_text):\n",
        "    print(input_text)\n",
        "    sentence = normalized_sentence(input_text)\n",
        "    print(sentence)\n",
        "    sentence = tokenizer.texts_to_sequences([sentence])\n",
        "    print(sentence)\n",
        "    sentence = pad_sequences(sentence, maxlen=229, truncating='pre')\n",
        "    result = label_encoder.inverse_transform(np.argmax(model.predict(sentence), axis=-1))[0]\n",
        "    proba =  np.max(model.predict(sentence))\n",
        "    print(result)\n",
        "    print(proba)\n",
        "    return result, proba\n",
        "\n",
        "def predict_proba(sentences):\n",
        "    # Preprocess each sentence\n",
        "    preprocessed_sentences = [normalized_sentence(sentence) for sentence in sentences]\n",
        "    sequences = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=300, truncating='pre')\n",
        "\n",
        "    # Predict probabilities for the padded sequences\n",
        "    return model.predict(padded_sequences)\n",
        "\n",
        "# Define prediction endpoint\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict_endpoint():\n",
        "    # Get input text from request\n",
        "    input_text = request.form['text']\n",
        "\n",
        "    # Make model predictions\n",
        "    prediction, prediction_prob = predict(input_text)\n",
        "    print(prediction)\n",
        "    print(prediction_prob)\n",
        "\n",
        "    # Generate LIME explanation\n",
        "    explanation = explainer.explain_instance(input_text, predict_proba, num_features=10, top_labels=6)\n",
        "\n",
        "    # Prepare response\n",
        "    response = {\n",
        "        'prediction': prediction,\n",
        "        'probability': str(prediction_prob),\n",
        "        'explanation': explanation.as_html()\n",
        "    }\n",
        "\n",
        "    return jsonify(response)\n",
        "\n",
        "# Define Flask routes\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "     return \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Emotion Prediction</title>\n",
        "    <style>\n",
        "        /* Input text style */\n",
        "        #textInput {\n",
        "            width: 100%;\n",
        "            padding: 10px;\n",
        "            font-size: 16px;\n",
        "            border: 1px solid #ccc;\n",
        "            border-radius: 5px;\n",
        "            box-sizing: border-box;\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "\n",
        "        /* Responsive iframe style */\n",
        "        .iframe-container {\n",
        "            position: relative;\n",
        "            overflow: auto;\n",
        "            width: 100%;\n",
        "            border: none;\n",
        "            padding-top: 56.25%; /* 16:9 aspect ratio */\n",
        "        }\n",
        "\n",
        "        .iframe-container iframe {\n",
        "            position: absolute;\n",
        "            top: 0;\n",
        "            left: 0;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            border: none;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h2>Emotion Prediction</h2>\n",
        "    <form id=\"predictionForm\">\n",
        "        <label for=\"textInput\">Enter Text:</label><br>\n",
        "        <input type=\"text\" id=\"textInput\" name=\"text\" placeholder=\"Type your text here...\">\n",
        "        <button type=\"submit\">Predict</button>\n",
        "    </form>\n",
        "    <div id=\"prediction\"></div>\n",
        "    <div class=\"iframe-container\">\n",
        "        <iframe id=\"explanationIframe\" title=\"Explanation\"></iframe>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        document.getElementById(\"predictionForm\").addEventListener(\"submit\", function(event) {\n",
        "            event.preventDefault();\n",
        "            const formData = new FormData(this);\n",
        "            const requestData = {\n",
        "                'text': formData.get('text')\n",
        "            };\n",
        "\n",
        "            fetch('/predict', {\n",
        "                method: 'POST',\n",
        "                body: new URLSearchParams(requestData),\n",
        "                headers: {\n",
        "                    'Content-Type': 'application/x-www-form-urlencoded'\n",
        "                }\n",
        "            })\n",
        "            .then(response => response.json())\n",
        "            .then(data => {\n",
        "                const predictionElement = document.getElementById(\"prediction\");\n",
        "                const explanationIframe = document.getElementById(\"explanationIframe\");\n",
        "\n",
        "                // Display prediction\n",
        "                predictionElement.innerHTML = `Predicted Emotion: ${data.prediction} (${(data.probability * 100).toFixed(2)}%)`;\n",
        "\n",
        "                // Update the iframe with the LIME explanation\n",
        "                const iframeDocument = explanationIframe.contentWindow.document;\n",
        "                iframeDocument.open();\n",
        "                iframeDocument.write(data.explanation);\n",
        "                iframeDocument.close();\n",
        "            })\n",
        "            .catch(error => console.error('Error:', error));\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "     \"\"\"\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMHR1tmGE8Nn",
        "outputId": "109dcef7-2d12-41e8-bcf5-50c04b103db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n",
            " * ngrok tunnel \"https://b1f0-34-80-41-120.ngrok-free.app\" -> \"http://127.0.0.1:5000/\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [08/May/2024 20:34:25] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [08/May/2024 20:34:25] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I feel awesome today\n",
            "feel awesome today\n",
            "[[2, 934, 55]]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "joy\n",
            "0.9680595\n",
            "joy\n",
            "0.9680595\n",
            "157/157 [==============================] - 81s 514ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/May/2024 20:36:01] \"POST /predict HTTP/1.1\" 200 -\n",
            "WARNING:pyngrok.process.ngrok:t=2024-05-08T21:24:11+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-c0b05282-ee57-4a54-91a5-5bfd1833984b acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 1835,
          "sourceId": 3176,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 605165,
          "sourceId": 1085454,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 1116138,
          "sourceId": 1874890,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30302,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}